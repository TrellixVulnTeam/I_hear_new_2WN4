{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a494a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import six\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "%matplotlib inline\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74c637",
   "metadata": {},
   "source": [
    "# Shape Detection Initial Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48400698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initShapeDetectionFunction():\n",
    "    global image_x, image_y, path, file, top_category_index, top_detection_model, stick_category_index, stick_detection_model\n",
    "    image_x = 640\n",
    "    image_y = 360\n",
    "\n",
    "    path = {\n",
    "    'topcam_folder':os.path.join('dataset', 'data3', 'topcam'),\n",
    "    'sidecam_folder':os.path.join('dataset', 'data3', 'side'),\n",
    "    'stickcam_folder':os.path.join('dataset', 'data3', 'stick'),\n",
    "    'top_checkpoint_path':os.path.join('Model', 'my_ssd_mobnet4'),\n",
    "    'stick_checkpoint_path':os.path.join('Model', 'my_stick_ssd_mobnet2')\n",
    "    }\n",
    "\n",
    "    file = {\n",
    "    'topcam_removeBG_model':os.path.join('Model', 'RemoveBottomBackground2.h5'),\n",
    "    'sidecam_removeBG_model':os.path.join('Model', 'RemoveBackgroundVer9.h5'),\n",
    "    'top_pipeline_config':os.path.join(path['top_checkpoint_path'], 'pipeline.config'),\n",
    "    'stick_pipeline_config':os.path.join(path['stick_checkpoint_path'], 'pipeline.config'),\n",
    "    'top_label_map':os.path.join('annotations', 'label_map.pbtxt'),\n",
    "    'stick_label_map':os.path.join('annotations', 'stick_label_map2.pbtxt')\n",
    "    }\n",
    "\n",
    "    top_category_index = label_map_util.create_category_index_from_labelmap(file['top_label_map'])\n",
    "    top_configs = config_util.get_configs_from_pipeline_file(file['top_pipeline_config'])\n",
    "    top_detection_model = model_builder.build(model_config = top_configs['model'], is_training=False)\n",
    "    top_ckpt = tf.compat.v2.train.Checkpoint(model = top_detection_model)\n",
    "    top_ckpt.restore(os.path.join(path['top_checkpoint_path'], 'ckpt-201')).expect_partial()\n",
    "\n",
    "    stick_category_index = label_map_util.create_category_index_from_labelmap(file['stick_label_map'])\n",
    "    stick_configs = config_util.get_configs_from_pipeline_file(file['stick_pipeline_config'])\n",
    "    stick_detection_model = model_builder.build(model_config = stick_configs['model'], is_training=False)\n",
    "    stick_ckpt = tf.compat.v2.train.Checkpoint(model = stick_detection_model)\n",
    "    stick_ckpt.restore(os.path.join(path['stick_checkpoint_path'], 'ckpt-201')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def bottom_detect_fn(image):\n",
    "    image, shapes = top_detection_model.preprocess(image)\n",
    "    prediction_dict = top_detection_model.predict(image, shapes)\n",
    "    detections = top_detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "@tf.function\n",
    "def stick_detect_fn(image):\n",
    "    image, shapes = stick_detection_model.preprocess(image)\n",
    "    prediction_dict = stick_detection_model.predict(image, shapes)\n",
    "    detections = stick_detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "def getCenterFromModel(detections, hight, width):\n",
    "    ##### input detections['detection_boxes'][max score index]\n",
    "    ##### output (x,y) \n",
    "    ymin = np.array(detections[0] * hight)\n",
    "    xmin = np.array(detections[1] * width)\n",
    "    ymax = np.array(detections[2] * hight)\n",
    "    xmax = np.array(detections[3] * width)\n",
    "    center_x = ((xmax - xmin)/2) + xmin\n",
    "    center_y = ((ymax - ymin)/2) + ymin\n",
    "    return center_x, center_y\n",
    "\n",
    "def rotatePointZaxis(angle, point):\n",
    "    ##### Rotation Matrix #####\n",
    "    theta = np.radians(angle)\n",
    "    [cos, sin] = np.cos(theta), np.sin(theta)\n",
    "    [x_new, y_new, z_new,  _] = [((point[0]*cos) - (point[1]*sin)), ((point[2]*sin) + (point[1]*cos)), point[2], 1]\n",
    "    point_new = [x_new, y_new, z_new]\n",
    "    \n",
    "    return point_new\n",
    "\n",
    "def rotatePointXaxis(angle, point):\n",
    "    ##### Rotation Matrix #####|\n",
    "    theta = np.radians(angle)\n",
    "    [cos, sin] = np.cos(theta), np.sin(theta)\n",
    "    [x_new, y_new, z_new,  _] = [point[0], ((point[1]*cos) - (point[2]*sin)), ((point[1]*sin) + (point[2]*cos)), 1]\n",
    "    point_new = [x_new, y_new, z_new]\n",
    "    \n",
    "    return point_new\n",
    "\n",
    "def transaltePointXaxis(x, point):\n",
    "    [x_new, y_new, z_new, _] = [point[0] + x, point[1], point[2], 1]\n",
    "    point_new = [x_new, y_new, z_new]\n",
    "\n",
    "    return point_new\n",
    "\n",
    "def translatePointZaxis(z, point):\n",
    "    [x_new, y_new, z_new, _] = [point[0], point[1], point[2] + z, 1]\n",
    "    point_new = [x_new, y_new, z_new]\n",
    "\n",
    "    return point_new\n",
    "\n",
    "def scaleMatrix(scale, point):\n",
    "    [x_new, y_new, z_new, _] = [point[0]*scale[0], point[1]*scale[1], point[2]*scale[2], 1]\n",
    "    point_new = [x_new, y_new, z_new]\n",
    "\n",
    "    return point_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5fb90",
   "metadata": {},
   "source": [
    "# Top Camera Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topcam_RemoveBG(image):\n",
    "    ##### return image with INPUT shape #####\n",
    "    src = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    [hight, width, _] = src.shape\n",
    "    src_resize = cv.resize(src, (image_x, image_y))\n",
    "    src_resize = src_resize / 255.0\n",
    "    \n",
    "    model = tf.keras.models.load_model(file['topcam_removeBG_model'])\n",
    "    predict = model.predict(np.array([src_resize]))\n",
    "    predict = predict.reshape(image_y, image_x)\n",
    "    \n",
    "    ret, predict = cv.threshold(predict, 0.2, 1.0, cv.THRESH_BINARY)\n",
    "    \n",
    "    predict = cv.resize(predict, (width, hight)).reshape(hight, width, 1)\n",
    "    res = np.multiply(src/255., np.repeat(predict, 3, axis = 2))\n",
    "    res = res * 255\n",
    "    output = res.astype(np.uint8)\n",
    "\n",
    "    return output\n",
    "\n",
    "def Bottom_Detection(image):\n",
    "    ##### return image with Input shape (360x640)#####\n",
    "    src = cv.resize(image, (image_x, image_y))\n",
    "    [hight,width,_] = src.shape\n",
    "    image_np = np.array(src).astype(np.uint8)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = bottom_detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    \n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes'] + label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                top_category_index,\n",
    "                use_normalized_coordinates = True,\n",
    "                max_boxes_to_draw = 2,\n",
    "                min_score_thresh = (0.18),\n",
    "                agnostic_mode = False)\n",
    "    \n",
    "\n",
    "    if(detections['detection_scores'][0] >= 0.18):\n",
    "        detected = True\n",
    "    else:\n",
    "        detected = False\n",
    "    \n",
    "    bottom_detect_point = getCenterFromModel(detections['detection_boxes'][0], hight, width)\n",
    "    \n",
    "    ##### Distance #####\n",
    "    #x_distance = bottom_pixel[0] - 316 \n",
    "    #y_distance = bottom_pixel[1] - 157\n",
    "    #distance = [x_distance, y_distance]\n",
    "    #\n",
    "    ###### X Axis Line #####\n",
    "    #cv.line(image_np_with_detections, (316, 0), (316, 360), (0, 255, 0), 2)\n",
    "    #\n",
    "    ###### Y Axis Line #####\n",
    "    #cv.line(image_np_with_detections, (0, 157), (640, 157), (255, 0, 0), 2)\n",
    "    #\n",
    "    ###### Connect Line #####\n",
    "    #cv.line(image_np_with_detections, (316, 157) , (int(center_x), int(center_y)), (0, 0, 255), 2)\n",
    "    \n",
    "    return image_np_with_detections, bottom_detect_point, detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd604b39",
   "metadata": {},
   "source": [
    "# Side Camera Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5631f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sidecam_RemoveBG(image):\n",
    "    ##### return image with (360x640) shape #####\n",
    "    src = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    [hight, width, _] = src.shape\n",
    "    src_resize = cv.resize(src, (256, 144))\n",
    "    src_resize = src_resize/255.0\n",
    "    \n",
    "    model = tf.keras.models.load_model(file['sidecam_removeBG_model'])\n",
    "    predict = model.predict(np.array([src_resize]))\n",
    "    predict = predict.reshape(144, 256)\n",
    "    \n",
    "    ret, predict = cv.threshold(predict, 0.59, 1.0, cv.THRESH_BINARY)\n",
    "    predict[predict != 0] = 1\n",
    "    predict = cv.resize(predict, (width, hight)).reshape(hight, width, 1)\n",
    "    #plt.imshow(predict, cmap = 'gray')\n",
    "    #plt.show()\n",
    "    res = np.multiply(src/255., np.repeat(predict, 3, axis = 2))\n",
    "    res = res * 255\n",
    "    output = res.astype(np.uint8)\n",
    "    output = cv.resize(output, (image_x, image_y))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def getMaxAreaContour(image):\n",
    "    ##### return max area contour #####\n",
    "    image = image.astype('uint8')\n",
    "    if(len(image.shape) != 3):\n",
    "        src_gray = image\n",
    "    else:\n",
    "        src_gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "        \n",
    "    src_gray = cv.medianBlur(src_gray, 15)\n",
    "    \n",
    "    _, thresh = cv.threshold(src_gray, 30, 255, cv.THRESH_BINARY)\n",
    "    contours , hierarchy = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "    max_area_countour = max(contours, key = cv.contourArea)\n",
    "    \n",
    "    return max_area_countour\n",
    "\n",
    "def getPercentSymmetric(image, deg, rot_point):\n",
    "    rotate_matrix = cv.getRotationMatrix2D(center = (rot_point[0], rot_point[1]), angle= int(deg), scale=1)\n",
    "    rotated_image = cv.warpAffine(src = image, M = rotate_matrix, dsize = (image.shape[1], image.shape[0]))\n",
    "\n",
    "    c = getMaxAreaContour(rotated_image)\n",
    "    x, y ,w, h = cv.boundingRect(c)\n",
    "    crop_rotate_image = rotated_image[0:(rot_point[1]*2), x:x+w]\n",
    "\n",
    "    mirror = np.flipud(crop_rotate_image)\n",
    "\n",
    "    intersec_image = cv.bitwise_and(cv.cvtColor(crop_rotate_image, cv.COLOR_RGB2GRAY), cv.cvtColor(mirror, cv.COLOR_RGB2GRAY))\n",
    "    intersec_image[intersec_image != 0] = 255\n",
    "\n",
    "    union_image = cv.bitwise_or(cv.cvtColor(crop_rotate_image, cv.COLOR_RGB2GRAY), cv.cvtColor(mirror, cv.COLOR_RGB2GRAY))\n",
    "    union_image[union_image != 0] = 255\n",
    "\n",
    "    intersec_area = cv.contourArea(getMaxAreaContour(intersec_image))\n",
    "    union_area = cv.contourArea(getMaxAreaContour(union_image))\n",
    "\n",
    "    cv.drawContours(crop_rotate_image, getMaxAreaContour(intersec_image), -1, (255, 0, 0), 2)\n",
    "\n",
    "    inersec_percentage = (intersec_area / union_area)*100\n",
    "    print('Intersection Percentage: ' + str(round(inersec_percentage)) + '%')\n",
    "    ##### X Axis On Side Camera #####\n",
    "    cv.line(rotated_image, (rot_point[0], 0), (rot_point[0], 360), (255, 0, 0), 2)\n",
    "    ##### Y Axis On Side Camera #####\n",
    "    cv.line(rotated_image, (0, rot_point[1]), (640, rot_point[1]), (0, 0, 255), 2)\n",
    "    \n",
    "    plt.imshow(cv.hconcat([cv.rotate(crop_rotate_image, cv.ROTATE_90_COUNTERCLOCKWISE), cv.rotate(mirror, cv.ROTATE_90_COUNTERCLOCKWISE)]))\n",
    "    plt.show()\n",
    "    plt.imshow(cv.hconcat([cv.rotate(intersec_image, cv.ROTATE_90_COUNTERCLOCKWISE), cv.rotate(union_image, cv.ROTATE_90_COUNTERCLOCKWISE)]), cmap = 'gray')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08dec9b",
   "metadata": {},
   "source": [
    "# Stick Camera Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f357cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectLeftStick(image):\n",
    "    ##### return image with (320x320) shape #####\n",
    "    ##### list index 0 means base of the stick\n",
    "    ##### list index 1 means end of the stick\n",
    "    ##### pixel index 0 means x coordinate\n",
    "    ##### pixel index 1 means y coordinate\n",
    "    src = cv.resize(image, (640, 360))\n",
    "    center_x = 435\n",
    "    center_y = 180\n",
    "    src = src[(center_y - center_y):(center_y + center_y), (center_x - center_y):(center_x + center_y)]\n",
    "    src = cv.resize(src, (320, 320))\n",
    "    [hight,width,_] = src.shape\n",
    "    image_np = np.array(src).astype(np.uint8)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    \n",
    "    detections = stick_detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    label_id_offset = 1\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64) + label_id_offset\n",
    "    base_index = np.where(detections['detection_classes'] == 1)[0][0]\n",
    "    end_index = np.where(detections['detection_classes'] == 2)[0][0]\n",
    "    image_np_with_detections = image_np.copy()\n",
    "                \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes'],\n",
    "                detections['detection_scores'],\n",
    "                stick_category_index,\n",
    "                use_normalized_coordinates = True,\n",
    "                max_boxes_to_draw = 2,\n",
    "                min_score_thresh = (0.2),\n",
    "                agnostic_mode = False)\n",
    "    \n",
    "    if(detections['detection_scores'][base_index] >= 0.2):\n",
    "        base_detected = True\n",
    "    else:\n",
    "        base_detected = False\n",
    "    \n",
    "    if(detections['detection_scores'][end_index] >= 0.2):\n",
    "        end_detected = True\n",
    "    else:\n",
    "        end_detected = False\n",
    "    \n",
    "    detected = [base_detected, end_detected]\n",
    "\n",
    "    ##### Point on (320x320) frame #####\n",
    "    base_point = getCenterFromModel(detections['detection_boxes'][base_index], hight, width)\n",
    "    end_point = getCenterFromModel(detections['detection_boxes'][end_index], hight, width)\n",
    "\n",
    "    ##### Scale to 360x640 frame include offset #####\n",
    "    scale_base_point = [(base_point[0]*1.125) + (center_x - center_y), (base_point[1]*1.125), 0]\n",
    "    scale_end_point = [(end_point[0]*1.125) + (center_x - center_y), (end_point[1]*1.125), 0]\n",
    "    \n",
    "    return image_np_with_detections, scale_base_point, scale_end_point, detected\n",
    "\n",
    "def detectRightStick(image):\n",
    "    ##### return image with (320x320) shape #####\n",
    "    ##### list index 0 means base of the stick\n",
    "    ##### list index 1 means end of the stick\n",
    "    ##### pixel index 0 means x coordinate\n",
    "    ##### pixel index 1 means y coordinate\n",
    "    src = cv.resize(image, (640, 360))\n",
    "    center_x = 353\n",
    "    center_y = 180\n",
    "    src = src[(center_y - center_y):(center_y + center_y), (center_x - center_y):(center_x + center_y)]\n",
    "    src = cv.resize(src, (320, 320))\n",
    "    [hight,width,_] = src.shape\n",
    "    image_np = np.array(src).astype(np.uint8)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    \n",
    "    detections = stick_detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    label_id_offset = 1\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64) + label_id_offset\n",
    "    base_index = np.where(detections['detection_classes'] == 1)[0][0]\n",
    "    end_index = np.where(detections['detection_classes'] == 2)[0][0]\n",
    "    image_np_with_detections = image_np.copy()\n",
    "                \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes'],\n",
    "                detections['detection_scores'],\n",
    "                stick_category_index,\n",
    "                use_normalized_coordinates = True,\n",
    "                max_boxes_to_draw = 2,\n",
    "                min_score_thresh = (0.2),\n",
    "                agnostic_mode = False)\n",
    "    \n",
    "    if(detections['detection_scores'][base_index] >= 0.2):\n",
    "        base_detected = True\n",
    "    else:\n",
    "        base_detected = False\n",
    "    \n",
    "    if(detections['detection_scores'][end_index] >= 0.2):\n",
    "        end_detected = True\n",
    "    else:\n",
    "        end_detected = False\n",
    "    \n",
    "    detected = [base_detected, end_detected]\n",
    "\n",
    "    ##### Point on (320x320) frame #####\n",
    "    base_point = getCenterFromModel(detections['detection_boxes'][base_index], hight, width)\n",
    "    end_point = getCenterFromModel(detections['detection_boxes'][end_index], hight, width)\n",
    "\n",
    "    ##### Scale to 360x640 frame include offset #####\n",
    "    scale_base_point = [(base_point[0]*1.125) + (center_x - center_y), (base_point[1]*1.125), 0]\n",
    "    scale_end_point = [(end_point[0]*1.125) + (center_x - center_y), (end_point[1]*1.125), 0]\n",
    "    \n",
    "    return image_np_with_detections, scale_base_point, scale_end_point, detected\n",
    "\n",
    "def getLengthAndAngle(base_point, end_point):\n",
    "    base_disparity = base_point[0] - base_point[1]\n",
    "    end_disparity = end_point[0] - end_point[1]\n",
    "\n",
    "    base_dept = (38 * 930) / (base_disparity * 2)\n",
    "    end_dept = (38 * 930) / (end_disparity * 2)\n",
    "\n",
    "    base_x = (base_dept * ((base_point[0]*2) - 640)) / 930\n",
    "    end_x = (end_dept * ((end_point[0]*2) - 640)) / 930\n",
    "\n",
    "    stick_angle = math.atan((base_x - end_x) / (base_dept - end_dept)) * (180/math.pi)\n",
    "    stick_length = math.sqrt( ((base_dept - end_dept)**2) + ((base_x - end_x)**2) )\n",
    "    \n",
    "    ##### negative means left screw #####\n",
    "    return stick_length, stick_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985dcfff",
   "metadata": {},
   "source": [
    "# All Code In Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c20933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectShape(side_img, imgL, imgR):\n",
    "    cam_angle = math.atan(180/(640 - 360)) * (180/math.pi)\n",
    "    imgL_detection, lbp, lep, left_detected = detectLeftStick(imgL)\n",
    "    imgR_detection, rbp, rep, right_detected = detectRightStick(imgR)\n",
    "    stick_length, stick_angle = getLengthAndAngle([lbp[0], rbp[0]], [lep[0], rep[0]])\n",
    "\n",
    "    trans_bts = transaltePointXaxis(-640, rbp)\n",
    "    rot_bts = rotatePointXaxis(90, trans_bts)\n",
    "    point_bts = rotatePointZaxis(cam_angle, rot_bts)\n",
    "    point_bts = [point_bts[0] + 405, point_bts[1], point_bts[2]]\n",
    "\n",
    "    if(left_detected[0] and right_detected[0] and left_detected[1] and right_detected[1]):\n",
    "        sidecam_removeBG = Sidecam_RemoveBG(side_img)\n",
    "        c = getMaxAreaContour(sidecam_removeBG)\n",
    "        end_index = (np.where(c[:,0,1] == round(point_bts[0])))[0][-1]\n",
    "        heightest_point = c[end_index][0]\n",
    "        min_index = (np.where(c[:,0,0] == min(c[:,0,0])))[0][0]\n",
    "        lowest_point = c[min_index][0]\n",
    "        rot_point = [round(lowest_point[0]), round(point_bts[0])]\n",
    "        height_length = heightest_point[0] - lowest_point[0]\n",
    "\n",
    "        offset_x = math.tan(np.radians(stick_angle)) * height_length\n",
    "        end_point = [heightest_point[0], point_bts[0] + offset_x]\n",
    "        getPercentSymmetric(sidecam_removeBG, stick_angle, rot_point)\n",
    "        cv.circle(sidecam_removeBG, (round(lowest_point[0]), round(point_bts[0])), 10, (0, 255, 0), 2)\n",
    "        cv.line(sidecam_removeBG, (rot_point[0], rot_point[1]), (round(end_point[0]), round(end_point[1])), (255, 255, 255), 2)\n",
    "        plt.imshow(sidecam_removeBG)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('CANNOT FIND STICK OF DURAIN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c3df2",
   "metadata": {},
   "source": [
    "# Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3171e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initShapeDetectionFunction()\n",
    "sidecam_pic_name = next(os.walk(path['sidecam_folder']))[2]\n",
    "imgL_pic_name = next(os.walk(os.path.join(path['stickcam_folder'], 'frame1')))[2]\n",
    "imgR_pic_name = next(os.walk(os.path.join(path['stickcam_folder'], 'frame2')))[2]\n",
    "cv_file = cv.FileStorage()\n",
    "cv_file.open('stereoMap.xml', cv.FileStorage_READ)\n",
    "cam_angle = math.atan(180/(640 - 360)) * (180/math.pi)\n",
    "\n",
    "stereoMapL_x = cv_file.getNode('stereoMapL_x').mat()\n",
    "stereoMapL_y = cv_file.getNode('stereoMapL_y').mat()\n",
    "stereoMapR_x = cv_file.getNode('stereoMapR_x').mat()\n",
    "stereoMapR_y = cv_file.getNode('stereoMapR_y').mat()\n",
    "\n",
    "imgL = cv.imread(os.path.join(path['stickcam_folder'], 'frame1', imgL_pic_name[2]))\n",
    "imgL = cv.remap(imgL, stereoMapL_x, stereoMapL_y, cv.INTER_LANCZOS4, cv.BORDER_CONSTANT, 0)\n",
    "\n",
    "imgR = cv.imread(os.path.join(path['stickcam_folder'], 'frame2', imgR_pic_name[2]))\n",
    "imgR = cv.remap(imgR, stereoMapR_x, stereoMapR_y, cv.INTER_LANCZOS4, cv.BORDER_CONSTANT, 0)\n",
    "\n",
    "side_img = cv.imread(os.path.join(path['sidecam_folder'], sidecam_pic_name[2]))\n",
    "\n",
    "detectShape(side_img, imgL, imgR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ecb311",
   "metadata": {},
   "source": [
    "# Random Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ RANDOM PICTURE #########################################################\n",
    "topcam_folder = next(os.walk(path['topcam_folder']))[1]\n",
    "sidecam_folder = next(os.walk(path['sidecam_folder']))[1]\n",
    "random_folder_number = random.randint(0, (len(sidecam_folder)-1))\n",
    "topcam_folder_path = os.path.join(path['topcam_folder'], topcam_folder[random_folder_number])\n",
    "sidecam_folder_path = os.path.join(path['sidecam_folder'], sidecam_folder[random_folder_number])\n",
    "\n",
    "topcam_pic_name = next(os.walk(topcam_folder_path))[2]\n",
    "sidecam_pic_name = next(os.walk(sidecam_folder_path))[2]\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "for i in range(len(topcam_pic_name)):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bcc50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mobnet",
   "language": "python",
   "name": "mobnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
