{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a494a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\thana\\\\Desktop\\\\TheShit\\\\DurianSang\\\\Mobnet'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import six\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "%matplotlib inline\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74c637",
   "metadata": {},
   "source": [
    "# Shape Detection Initial Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48400698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shape_Detection_Initial():\n",
    "    global image_x, image_y, path, file, top_category_index, top_detection_model, stick_category_index, stick_detection_model\n",
    "    image_x = 640\n",
    "    image_y = 360\n",
    "\n",
    "    path = {\n",
    "    'topcam_folder':os.path.join('dataset', 'topcam'),\n",
    "    'sidecam_folder':os.path.join('dataset', 'sidecam'),\n",
    "    'stickcam_folder':os.path.join('dataset', 'stickcam'),\n",
    "    'top_checkpoint_path':os.path.join('Model', 'my_ssd_mobnet4'),\n",
    "    'stick_checkpoint_path':os.path.join('Model', 'my_stick_ssd_mobnet2')\n",
    "    }\n",
    "\n",
    "    file = {\n",
    "    'topcam_removeBG_model':os.path.join('Model', 'RemoveBottomBackground2.h5'),\n",
    "    'sidecam_removeBG_model':os.path.join('Model', 'RemoveBackgroundVer9.h5'),\n",
    "    'top_pipeline_config':os.path.join(path['top_checkpoint_path'], 'pipeline.config'),\n",
    "    'stick_pipeline_config':os.path.join(path['stick_checkpoint_path'], 'pipeline.config'),\n",
    "    'top_label_map':os.path.join('annotations', 'label_map.pbtxt'),\n",
    "    'stick_label_map':os.path.join('annotations', 'stick_label_map2.pbtxt')\n",
    "    }\n",
    "\n",
    "    top_category_index = label_map_util.create_category_index_from_labelmap(file['top_label_map'])\n",
    "    top_configs = config_util.get_configs_from_pipeline_file(file['top_pipeline_config'])\n",
    "    top_detection_model = model_builder.build(model_config = top_configs['model'], is_training=False)\n",
    "    top_ckpt = tf.compat.v2.train.Checkpoint(model = top_detection_model)\n",
    "    top_ckpt.restore(os.path.join(path['top_checkpoint_path'], 'ckpt-201')).expect_partial()\n",
    "\n",
    "    stick_category_index = label_map_util.create_category_index_from_labelmap(file['stick_label_map'])\n",
    "    stick_configs = config_util.get_configs_from_pipeline_file(file['stick_pipeline_config'])\n",
    "    stick_detection_model = model_builder.build(model_config = stick_configs['model'], is_training=False)\n",
    "    stick_ckpt = tf.compat.v2.train.Checkpoint(model = stick_detection_model)\n",
    "    stick_ckpt.restore(os.path.join(path['stick_checkpoint_path'], 'ckpt-201')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def bottom_detect_fn(image):\n",
    "    image, shapes = top_detection_model.preprocess(image)\n",
    "    prediction_dict = top_detection_model.predict(image, shapes)\n",
    "    detections = top_detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "@tf.function\n",
    "def stick_detect_fn(image):\n",
    "    image, shapes = stick_detection_model.preprocess(image)\n",
    "    prediction_dict = stick_detection_model.predict(image, shapes)\n",
    "    detections = stick_detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "def Get_Center_From_Model(detections, hight, width):\n",
    "    ##### input detections['detection_boxes'][max score index]\n",
    "    ##### output (x,y) \n",
    "    ymin = np.array(detections[0] * hight)\n",
    "    xmin = np.array(detections[1] * width)\n",
    "    ymax = np.array(detections[2] * hight)\n",
    "    xmax = np.array(detections[3] * width)\n",
    "    center_x = ((xmax - xmin)/2) + xmin\n",
    "    center_y = ((ymax - ymin)/2) + ymin\n",
    "    return center_x, center_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5fb90",
   "metadata": {},
   "source": [
    "# Top Camera Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topcam_RemoveBG(image):\n",
    "    ##### return image with INPUT shape #####\n",
    "    src = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    [hight, width, _] = src.shape\n",
    "    src_resize = cv.resize(src, (image_x, image_y))\n",
    "    src_resize = src_resize / 255.0\n",
    "    \n",
    "    model = tf.keras.models.load_model(file['topcam_removeBG_model'])\n",
    "    predict = model.predict(np.array([src_resize]))\n",
    "    predict = predict.reshape(image_y, image_x)\n",
    "    \n",
    "    ret, predict = cv.threshold(predict, 0.2, 1.0, cv.THRESH_BINARY)\n",
    "    \n",
    "    predict = cv.resize(predict, (width, hight)).reshape(hight, width, 1)\n",
    "    res = np.multiply(src/255., np.repeat(predict, 3, axis = 2))\n",
    "    res = res * 255\n",
    "    output = res.astype(np.uint8)\n",
    "\n",
    "    return output\n",
    "\n",
    "def Bottom_Detection(image):\n",
    "    ##### return image with Input shape (360x640)#####\n",
    "    src = cv.resize(image, (image_x, image_y))\n",
    "    [hight,width,_] = src.shape\n",
    "    image_np = np.array(src).astype(np.uint8)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = bottom_detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    \n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes'] + label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                top_category_index,\n",
    "                use_normalized_coordinates = True,\n",
    "                max_boxes_to_draw = 2,\n",
    "                min_score_thresh = (0.18),\n",
    "                agnostic_mode = False)\n",
    "    \n",
    "\n",
    "    if(detections['detection_scores'][0] >= 0.18):\n",
    "        detected = True\n",
    "    else:\n",
    "        detected = False\n",
    "    \n",
    "    bottom_detect_point = Get_Center_From_Model(detections['detection_boxes'][0], hight, width)\n",
    "    \n",
    "    ##### Distance #####\n",
    "    #x_distance = bottom_pixel[0] - 316 \n",
    "    #y_distance = bottom_pixel[1] - 157\n",
    "    #distance = [x_distance, y_distance]\n",
    "    #\n",
    "    ###### X Axis Line #####\n",
    "    #cv.line(image_np_with_detections, (316, 0), (316, 360), (0, 255, 0), 2)\n",
    "    #\n",
    "    ###### Y Axis Line #####\n",
    "    #cv.line(image_np_with_detections, (0, 157), (640, 157), (255, 0, 0), 2)\n",
    "    #\n",
    "    ###### Connect Line #####\n",
    "    #cv.line(image_np_with_detections, (316, 157) , (int(center_x), int(center_y)), (0, 0, 255), 2)\n",
    "    \n",
    "    return image_np_with_detections, bottom_detect_point, detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd604b39",
   "metadata": {},
   "source": [
    "# Side Camera Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5631f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sidecam_RemoveBG(image):\n",
    "    ##### return image with (360x640) shape #####\n",
    "    src = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    [hight, width, _] = src.shape\n",
    "    src_resize = cv.resize(src, (256, 144))\n",
    "    src_resize = src_resize/255.0\n",
    "    \n",
    "    model = tf.keras.models.load_model(file['sidecam_removeBG_model'])\n",
    "    predict = model.predict(np.array([src_resize]))\n",
    "    predict = predict.reshape(144, 256)\n",
    "    \n",
    "    ret, predict = cv.threshold(predict, 0.59, 1.0, cv.THRESH_BINARY)\n",
    "    predict[predict != 0] = 1\n",
    "    predict = cv.resize(predict, (width, hight)).reshape(hight, width, 1)\n",
    "    #plt.imshow(predict, cmap = 'gray')\n",
    "    #plt.show()\n",
    "    res = np.multiply(src/255., np.repeat(predict, 3, axis = 2))\n",
    "    res = res * 255\n",
    "    output = res.astype(np.uint8)\n",
    "    output = cv.resize(output, (image_x, image_y))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def Max_Area_Contour(image):\n",
    "    ##### return max area contour #####\n",
    "    image = image.astype('uint8')\n",
    "    if(len(image.shape) != 3):\n",
    "        src_gray = image\n",
    "    else:\n",
    "        src_gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "        \n",
    "    src_gray = cv.medianBlur(src_gray, 15)\n",
    "    \n",
    "    _, thresh = cv.threshold(src_gray, 30, 255, cv.THRESH_BINARY)\n",
    "    contours , hierarchy = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "    max_area_countour = max(contours, key = cv.contourArea)\n",
    "    \n",
    "    return max_area_countour\n",
    "\n",
    "def Point_Cam_Frame(deg, x_top, y_top):\n",
    "    ##### Rotation Matrix #####\n",
    "    theta = np.radians(deg)\n",
    "    [cos, sin] = np.cos(theta), np.sin(theta)\n",
    "    [x_cam, y_cam, _] = [((x_top*cos) - (y_top*sin)), ((x_top*sin) + (y_top*cos)), 1]\n",
    "    bottom_point = [x_cam, y_cam]\n",
    "    \n",
    "    return bottom_point\n",
    "\n",
    "def Find_Percent_Symmetric(image, deg, rot_point):\n",
    "    rotate_matrix = cv.getRotationMatrix2D(center = (rot_point[0], rot_point[1]), angle= int(deg), scale=1)\n",
    "    rotated_image = cv.warpAffine(src = image, M = rotate_matrix, dsize = (image.shape[1], image.shape[0]))\n",
    "\n",
    "    c = Max_Area_Contour(rotated_image)\n",
    "    x, y ,w, h = cv.boundingRect(c)\n",
    "    crop_rotate_image = rotated_image[0:(rot_point[1]*2), x:x+w]\n",
    "\n",
    "    mirror = np.flipud(crop_rotate_image)\n",
    "\n",
    "    intersec_image = cv.bitwise_and(cv.cvtColor(crop_rotate_image, cv.COLOR_RGB2GRAY), cv.cvtColor(mirror, cv.COLOR_RGB2GRAY))\n",
    "    intersec_image[intersec_image != 0] = 255\n",
    "\n",
    "    union_image = cv.bitwise_or(cv.cvtColor(crop_rotate_image, cv.COLOR_RGB2GRAY), cv.cvtColor(mirror, cv.COLOR_RGB2GRAY))\n",
    "    union_image[union_image != 0] = 255\n",
    "\n",
    "    intersec_area = cv.contourArea(Max_Area_Contour(intersec_image))\n",
    "    union_area = cv.contourArea(Max_Area_Contour(union_image))\n",
    "\n",
    "    cv.drawContours(crop_rotate_image, Max_Area_Contour(intersec_image), -1, (255, 0, 0), 2)\n",
    "\n",
    "    inersec_percentage = (intersec_area / union_area)*100\n",
    "    print('Intersection Percentage: ' + str(round(inersec_percentage)) + '%')\n",
    "    ##### X Axis On Side Camera #####\n",
    "    cv.line(rotated_image, (rot_point[0], 0), (rot_point[0], 360), (255, 0, 0), 2)\n",
    "    ##### Y Axis On Side Camera #####\n",
    "    cv.line(rotated_image, (0, rot_point[1]), (640, rot_point[1]), (0, 0, 255), 2)\n",
    "    \n",
    "    plt.imshow(cv.hconcat([cv.rotate(crop_rotate_image, cv.ROTATE_90_COUNTERCLOCKWISE), cv.rotate(mirror, cv.ROTATE_90_COUNTERCLOCKWISE)]))\n",
    "    plt.show()\n",
    "    plt.imshow(cv.hconcat([cv.rotate(intersec_image, cv.ROTATE_90_COUNTERCLOCKWISE), cv.rotate(union_image, cv.ROTATE_90_COUNTERCLOCKWISE)]), cmap = 'gray')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08dec9b",
   "metadata": {},
   "source": [
    "# Stick Camera Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f357cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stick_Detection(image):\n",
    "    ##### return image with (320x320) shape #####\n",
    "    ##### list index 0 means base of the stick\n",
    "    ##### list index 1 means end of the stick\n",
    "    ##### pixel index 0 means x coordinate\n",
    "    ##### pixel index 1 means y coordinate\n",
    "    center_x = 960\n",
    "    center_y = 540\n",
    "    src = image[center_y - 540:center_y + 540 ,center_x - 540:center_x + 540]\n",
    "    src = cv.resize(src, (320, 320))\n",
    "    [hight,width,_] = src.shape\n",
    "    image_np = np.array(src).astype(np.uint8)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    \n",
    "    detections = stick_detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    label_id_offset = 1\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64) + label_id_offset\n",
    "    base_index = np.where(detections['detection_classes'] == 1)[0][0]\n",
    "    end_index = np.where(detections['detection_classes'] == 2)[0][0]\n",
    "    image_np_with_detections = image_np.copy()\n",
    "                \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes'],\n",
    "                detections['detection_scores'],\n",
    "                stick_category_index,\n",
    "                use_normalized_coordinates = True,\n",
    "                max_boxes_to_draw = 2,\n",
    "                min_score_thresh = (0.2),\n",
    "                agnostic_mode = False)\n",
    "    \n",
    "    if(detections['detection_scores'][base_index] >= 0.2):\n",
    "        base_detected = True\n",
    "    else:\n",
    "        base_detected = False\n",
    "    \n",
    "    if(detections['detection_scores'][end_index] >= 0.2):\n",
    "        end_detected = True\n",
    "    else:\n",
    "        end_detected = False\n",
    "    \n",
    "    detected = [base_detected, end_detected]\n",
    "\n",
    "    ##### Point on (320x320) frame #####\n",
    "    base_point = Get_Center_From_Model(detections['detection_boxes'][base_index], hight, width)\n",
    "    end_point = Get_Center_From_Model(detections['detection_boxes'][end_index], hight, width)\n",
    "\n",
    "    ##### Scale to 360x640 frame include offset #####\n",
    "    scale_base_point = [(base_point[0]*1.125) + 140, (base_point[1]*1.125)]\n",
    "\n",
    "    ##### Rotation 180 degrees on y axis #####\n",
    "    base_rot_y_point = [640 - scale_base_point[0], scale_base_point[1]]\n",
    "\n",
    "    base_on_top_point[0] = (base_on_top_point[0]*50/100) + 160 - 13\n",
    "    base_on_top_point[1] = (base_on_top_point[1]*50/100) + 90 - 23\n",
    "    \n",
    "    return image_np_with_detections, base_on_top_point, end_point, detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc73100",
   "metadata": {},
   "source": [
    "# RUN ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524271d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Shape_Detection_Initial()\n",
    "topcam_folder = next(os.walk(path['topcam_folder']))[1]\n",
    "for i in topcam_folder:\n",
    "    topcam_folder_path = os.path.join(path['topcam_folder'], str(i))\n",
    "    sidecam_folder_path = os.path.join(path['sidecam_folder'], str(i))\n",
    "    stickcam_folder_path = os.path.join(path['stickcam_folder'], str(i))\n",
    "\n",
    "    topcam_pic_name = next(os.walk(topcam_folder_path))[2]\n",
    "    sidecam_pic_name = next(os.walk(sidecam_folder_path))[2]\n",
    "    stickcam_pic_name = next(os.walk(stickcam_folder_path))[2]\n",
    "\n",
    "\n",
    "    for j in range(len(sidecam_pic_name)):\n",
    "        topcam_pic_path = os.path.join(topcam_folder_path, topcam_pic_name[j])\n",
    "        topcam_image = cv.imread(topcam_pic_path, cv.IMREAD_COLOR)\n",
    "        sidecam_pic_path = os.path.join(sidecam_folder_path, sidecam_pic_name[j])\n",
    "        sidecam_image = cv.imread(sidecam_pic_path, cv.IMREAD_COLOR)\n",
    "        stickcam_pic_path = os.path.join(stickcam_folder_path, stickcam_pic_name[j])\n",
    "        stickcam_image = cv.imread(stickcam_pic_path, cv.IMREAD_COLOR)\n",
    "        #ref_path = os.path.join('Ref', '2022-07-14_17-14-27.jpg')\n",
    "        #ref_image = cv.imread(ref_path, cv.IMREAD_COLOR)\n",
    "        #ref_image = cv.resize(ref_image, (image_x, image_y))\n",
    "        \n",
    "        ##### Stick Camera Part #####\n",
    "        stick_detection_image, base_on_top_point, end_point, detected = Stick_Detection(stickcam_image)\n",
    "        stick_point = Point_Cam_Frame(45, base_on_top_point[0], base_on_top_point[1])\n",
    "        stick_y_distance = (math.sqrt((stick_point[0] - base_on_top_point[0])**2 + (stick_point[1] - base_on_top_point[1])**2)) * 0.7\n",
    "        ##### Top Camera Part #####\n",
    "        topcam_removeBG = Topcam_RemoveBG(topcam_image)\n",
    "        buttom_detection, bottom_detect_point, bottom_detected = Bottom_Detection(topcam_removeBG)\n",
    "        bottom_point = Point_Cam_Frame(45, bottom_detect_point[0], bottom_detect_point[1])\n",
    "        y_distance = (math.sqrt((bottom_point[0] - base_on_top_point[0])**2 + (bottom_point[1] - base_on_top_point[1])**2)) * 0.7  \n",
    "        \n",
    "        ##### X Axis Line #####\n",
    "        cv.line(buttom_detection, (round(base_on_top_point[0]), 0), (round(base_on_top_point[0]), 360), (0, 255, 0), 2)\n",
    "        ##### Y Axis Line #####\n",
    "        cv.line(buttom_detection, (0, round(base_on_top_point[1])), (640, round(base_on_top_point[1])), (255, 0, 0), 2)\n",
    "        ##### Connect Line #####\n",
    "        cv.line(buttom_detection, (round(base_on_top_point[0]), round(base_on_top_point[1])) , (round(bottom_detect_point[0]), round(bottom_detect_point[1])), (0, 0, 255), 2)\n",
    "        ##### Draw Circle ######\n",
    "        cv.circle(buttom_detection, (round(base_on_top_point[0]), round(base_on_top_point[1])), 10, (0, 255, 0), 2)\n",
    "        plt.imshow(buttom_detection)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        #print('base coordinate: (' + str(round(base_on_top_point[0])) + ', ' + str(round(base_on_top_point[1])) + ')')\n",
    "        #print('bottom coordinate: (' + str(round(bottom_detect_point[0])) + ', ' + str(round(bottom_detect_point[1])) + ')')\n",
    "\n",
    "        #x_distance = bottom_detect_point[0] - (base_on_top_point[0]) \n",
    "        #y_distance = bottom_detect_point[1] - (base_on_top_point[1])\n",
    "        #distance = [x_distance, y_distance]\n",
    "        #print('X distance: ' + str(round(x_distance)))\n",
    "        #print('Y distance: ' + str(round(y_distance)))\n",
    "\n",
    "        ##### Side Camera Part #####\n",
    "        if(bottom_detected):\n",
    "            sidecam_removeBG = Sidecam_RemoveBG(sidecam_image)\n",
    "            c = Max_Area_Contour(sidecam_removeBG)\n",
    "            end_index = (np.where(c[:,0,1] == round(y_distance)))[0][-1]\n",
    "            end_point = c[end_index][0]\n",
    "            #max_index = (np.where(c[:,0,0] == max(c[:,0,0])))[0][0]\n",
    "            #heightest_point = c[max_index][0]\n",
    "            min_index = (np.where(c[:,0,0] == min(c[:,0,0])))[0][0]\n",
    "            lowest_point = c[min_index][0]\n",
    "            #z_durian_height = heightest_point[0]\n",
    "            rot_point = [round(lowest_point[0]), round(stick_y_distance)]\n",
    "            durian_angle = (math.atan2((int(y_distance - rot_point[1])), (int(end_point[0] - rot_point[0])))) * (180/math.pi)\n",
    "            \n",
    "            Find_Percent_Symmetric(sidecam_removeBG, durian_angle, rot_point)\n",
    "\n",
    "            ##### X Axis On Side Camera #####\n",
    "            cv.line(sidecam_removeBG, (rot_point[0], 0), (rot_point[0], 360), (0, 255, 0), 2)\n",
    "            ##### Y Axis On Side Camera #####\n",
    "            cv.line(sidecam_removeBG, (0, rot_point[1]), (640, rot_point[1]), (0, 0, 255), 2)\n",
    "            ##### Orientation line #####\n",
    "            cv.line(sidecam_removeBG, (rot_point[0], rot_point[1]), (int(end_point[0]), int(end_point[1])), (255, 255, 255), 2)\n",
    "\n",
    "            plt.imshow(sidecam_removeBG)\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print('CANNOT FIND BOTTOM OF THIS OBJECT')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ecb311",
   "metadata": {},
   "source": [
    "# Random Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ RANDOM PICTURE #########################################################\n",
    "topcam_folder = next(os.walk(path['topcam_folder']))[1]\n",
    "sidecam_folder = next(os.walk(path['sidecam_folder']))[1]\n",
    "random_folder_number = random.randint(0, (len(sidecam_folder)-1))\n",
    "topcam_folder_path = os.path.join(path['topcam_folder'], topcam_folder[random_folder_number])\n",
    "sidecam_folder_path = os.path.join(path['sidecam_folder'], sidecam_folder[random_folder_number])\n",
    "\n",
    "topcam_pic_name = next(os.walk(topcam_folder_path))[2]\n",
    "sidecam_pic_name = next(os.walk(sidecam_folder_path))[2]\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "for i in range(len(topcam_pic_name)):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bcc50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mobnet",
   "language": "python",
   "name": "mobnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
